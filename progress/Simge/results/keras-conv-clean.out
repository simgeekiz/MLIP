Loading data...
Preprocessing...
Splitting...
Setting optimizer...
Creating the network...

Network summary:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 28, 28, 32)        25632     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 14, 14, 32)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               802944    
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
Output_Layer (Dense)         (None, 10)                1290      
=================================================================
Total params: 830,698
Trainable params: 830,698
Non-trainable params: 0
_________________________________________________________________
None
Compiling...
Augmenting...
Fitting...
Epoch 1/30
 - 894s - loss: 0.5147 - acc: 0.8356 - val_loss: 0.0750 - val_acc: 0.9769
Epoch 2/30
 - 915s - loss: 0.2041 - acc: 0.9384 - val_loss: 0.0530 - val_acc: 0.9860
Epoch 3/30
 - 497s - loss: 0.1507 - acc: 0.9543 - val_loss: 0.0465 - val_acc: 0.9864
Epoch 4/30
 - 295s - loss: 0.1250 - acc: 0.9636 - val_loss: 0.0422 - val_acc: 0.9869
Epoch 5/30
 - 252s - loss: 0.1115 - acc: 0.9669 - val_loss: 0.0370 - val_acc: 0.9888
Epoch 6/30
 - 235s - loss: 0.1003 - acc: 0.9707 - val_loss: 0.0353 - val_acc: 0.9879
Epoch 7/30
 - 257s - loss: 0.0913 - acc: 0.9723 - val_loss: 0.0336 - val_acc: 0.9898
Epoch 8/30
 - 240s - loss: 0.0860 - acc: 0.9748 - val_loss: 0.0297 - val_acc: 0.9905
Epoch 9/30
 - 248s - loss: 0.0804 - acc: 0.9757 - val_loss: 0.0316 - val_acc: 0.9912
Epoch 10/30
 - 248s - loss: 0.0758 - acc: 0.9765 - val_loss: 0.0300 - val_acc: 0.9898
Epoch 11/30
 - 535s - loss: 0.0725 - acc: 0.9772 - val_loss: 0.0237 - val_acc: 0.9924
Epoch 12/30
 - 911s - loss: 0.0716 - acc: 0.9787 - val_loss: 0.0271 - val_acc: 0.9914
Epoch 13/30
 - 898s - loss: 0.0678 - acc: 0.9799 - val_loss: 0.0214 - val_acc: 0.9933
Epoch 14/30
 - 926s - loss: 0.0627 - acc: 0.9817 - val_loss: 0.0301 - val_acc: 0.9919
Epoch 15/30
 - 940s - loss: 0.0664 - acc: 0.9801 - val_loss: 0.0231 - val_acc: 0.9921
Epoch 16/30
 - 955s - loss: 0.0624 - acc: 0.9819 - val_loss: 0.0249 - val_acc: 0.9924
Epoch 17/30
 - 893s - loss: 0.0576 - acc: 0.9824 - val_loss: 0.0300 - val_acc: 0.9924

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 18/30
 - 891s - loss: 0.0516 - acc: 0.9846 - val_loss: 0.0212 - val_acc: 0.9933
Epoch 19/30
 - 887s - loss: 0.0461 - acc: 0.9864 - val_loss: 0.0250 - val_acc: 0.9933
Epoch 20/30
 - 880s - loss: 0.0464 - acc: 0.9858 - val_loss: 0.0250 - val_acc: 0.9931

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 21/30
 - 467s - loss: 0.0410 - acc: 0.9879 - val_loss: 0.0209 - val_acc: 0.9936
Epoch 22/30
 - 280s - loss: 0.0413 - acc: 0.9878 - val_loss: 0.0213 - val_acc: 0.9933
Epoch 23/30
 - 249s - loss: 0.0396 - acc: 0.9878 - val_loss: 0.0194 - val_acc: 0.9943
Epoch 24/30
 - 250s - loss: 0.0381 - acc: 0.9883 - val_loss: 0.0215 - val_acc: 0.9940
Epoch 25/30
 - 229s - loss: 0.0397 - acc: 0.9886 - val_loss: 0.0217 - val_acc: 0.9931
Epoch 26/30
 - 248s - loss: 0.0379 - acc: 0.9891 - val_loss: 0.0218 - val_acc: 0.9933
Epoch 27/30
 - 243s - loss: 0.0381 - acc: 0.9888 - val_loss: 0.0210 - val_acc: 0.9929

Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 28/30
 - 303s - loss: 0.0347 - acc: 0.9897 - val_loss: 0.0204 - val_acc: 0.9940
Epoch 29/30
 - 887s - loss: 0.0324 - acc: 0.9904 - val_loss: 0.0211 - val_acc: 0.9940
Epoch 30/30
 - 905s - loss: 0.0341 - acc: 0.9899 - val_loss: 0.0203 - val_acc: 0.9938

Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001.
Fitting took 281.0135440349579 minutes
Predicting...
>>> Submission saved under 'data/results/'
